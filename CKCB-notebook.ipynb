{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x0000016D7A0E1A50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\owais\\Desktop\\Educational platform\\Gemini-CKCB\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 790, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\owais\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1494, in enumerate\n",
      "    def enumerate():\n",
      "    \n",
      "KeyboardInterrupt: \n",
      "c:\\Users\\owais\\Desktop\\Educational platform\\Gemini-CKCB\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from google.generativeai.types.safety_types import HarmBlockThreshold, HarmCategory\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.llms import Replicate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='I\n",
      "/G4C/G61/G79/G69/G6E/G67/G20/G50/G6C/G61/G6E/G73\n",
      "1.Sun Tzu said : The art of war is of vital importanceto\n",
      "the State.\n",
      "2. It is a matter of life and death, a road either to safe-\n",
      "ty or to ruin. Hence it is a subject of inquiry which canon no account be neglected.\n",
      "3. The art of war, then, is governed by five\n",
      "constantfactors, to be taken into account in one’s delib-erations, when seeking to determine the conditionsobtaining in the field.\n",
      "4. These are: \n",
      "(1) The Moral Law; (2) Heaven; (3) Earth; (4) The Commander; (5) Method and discipline.\n",
      "5,6. The Moral Law causes the people to be in com-\n",
      "plete accord with their ruler, so that they will followhim regardless of their lives, undismayed by any dan-ger.\n",
      "7. Heaven signifies night and day, cold and heat, times\n",
      "and seasons.\n",
      "1\n",
      "/G53/G75/G6E/G20/G54/G7A/G75/G20/G6F/G6E/G20/G74/G68/G65/G20/G41/G72/G74/G20/G6F/G66/G20/G57/G61/G72' metadata={'source': 'AOW.pdf', 'page': 3}\n"
     ]
    }
   ],
   "source": [
    "path = \"AOW.pdf\"\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "pdf_loader = PyPDFLoader(path)\n",
    "pages = pdf_loader.load_and_split()\n",
    "print(pages[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "DB = Chroma.from_documents(pages, embeddings)\n",
    "retriever = DB.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLICATE_API_TOKEN = os.getenv(\"REPLICATE_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "temperature was transferred to model_kwargs.\n",
      "                    Please confirm that temperature is what you intended.\n",
      "top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n",
      "top_k was transferred to model_kwargs.\n",
      "                    Please confirm that top_k is what you intended.\n",
      "max_output_tokens was transferred to model_kwargs.\n",
      "                    Please confirm that max_output_tokens is what you intended.\n",
      "api_token was transferred to model_kwargs.\n",
      "                    Please confirm that api_token is what you intended.\n"
     ]
    }
   ],
   "source": [
    "LLama_3 = Replicate(\n",
    "        model=\"meta/meta-llama-3-8b\",\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        top_k=55,\n",
    "        max_output_tokens=5000,\n",
    "        api_token=REPLICATE_API_TOKEN\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\owais\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 26, 'source': 'AOW.pdf'}, page_content='34. The five elements (water, fire, wood, metal, earth)\\nare not always equally predominant; the four seasonsmake way for each other in turn. There are short daysand long; the moon has its periods of waning and wax-ing.\\n24\\n/G53/G75/G6E/G20/G54/G7A/G75/G20/G6F/G6E/G20/G74/G68/G65/G20/G41/G72/G74/G20/G6F/G66/G20/G57/G61/G72'),\n",
       " Document(metadata={'page': 13, 'source': 'AOW.pdf'}, page_content='(4) He will win who, prepared himself, waits to take\\nthe enemy unprepared.(5) He will win who has military capacity and is notinterfered with by the sovereign.\\n18. Hence the saying:  If you know the enemy and\\nknow yourself, you need not fear the result of a hun-dred battles. If you know yourself but not the enemy,for every victory gained you will also suffer a defeat. Ifyou know neither the enemy nor yourself, you will suc-cumb in every battle.\\n11\\n/G53/G75/G6E/G20/G54/G7A/G75/G20/G6F/G6E/G20/G74/G68/G65/G20/G41/G72/G74/G20/G6F/G66/G20/G57/G61/G72'),\n",
       " Document(metadata={'page': 5, 'source': 'AOW.pdf'}, page_content='(6) On which side are officers and men more high-\\nly trained?(7) In which army is there the greaterconstancy both in reward and punishment?\\n14. By means of these seven considerations I can fore-\\ncast victory or defeat.\\n15. The general that hearkens to my counsel and\\nactsupon it, will conquer:  let such a one be retained incommand! The general that hearkens not to my coun-sel nor acts upon it, will suffer defeat:—let such a onebe dismissed!\\n16. While heading the profit of my counsel,avail your-\\nself also of any helpful circumstances over and beyondthe ordinary rules.\\n17. According as circumstances are favorable, one\\nshould modify one’s plans.\\n18. All warfare is based on deception.\\n19. Hence, when able to attack, we must seem\\nunable; when using our forces, we must seem inactive;when weare near, we must make the enemy believe weare far away; when far away, we must make himbelieve we are near.\\n20. Hold out baits to entice the enemy. Feign disor-\\nder, and crush him.\\n3\\n/G53/G75/G6E/G20/G54/G7A/G75/G20/G6F/G6E/G20/G74/G68/G65/G20/G41/G72/G74/G20/G6F/G66/G20/G57/G61/G72')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"What are the 5 constant factors which govern the art of war?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "Gemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",\n",
    "                                google_api_key=GOOGLE_API_KEY,\n",
    "                                safety_settings=safety_settings,\n",
    "                                temperature=0.7,\n",
    "                                top_p=0.9,\n",
    "                                top_k=55,\n",
    "                                max_output_tokens=5000\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_google_vertexai import HarmBlockThreshold, HarmCategory\n",
    "\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "Gemini = VertexAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    project=\"llama-ckcb\",\n",
    "    location=\"us-central1\",\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    #top_k=55,\n",
    "    max_output_tokens=5000)\n",
    "\n",
    "question_model = VertexAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    project=\"llama-ckcb\",\n",
    "    location=\"us-central1\",\n",
    "    temperature=0.5,  # Lowered temperature for more focused outputs\n",
    "    top_p=0.7,        # Slightly reduced for more precise output\n",
    "    #top_k=40,         # Slightly reduced for more precise output\n",
    "    max_output_tokens=250  # Reduced to limit the length of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "generation_config = {\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.9,\n",
    "  \"top_k\": 55,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,\n",
    "  safety_settings = safety_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    google_api_key=GOOGLE_API_KEY,\n",
    "    safety_settings=safety_settings,\n",
    "    temperature=0.5,  # Lowered temperature for more focused outputs\n",
    "    top_p=0.7,        # Slightly reduced for more precise output\n",
    "    top_k=40,         # Slightly reduced for more precise output\n",
    "    max_output_tokens=250  # Reduced to limit the length of the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator_template = \"\"\"\n",
    "chat history: {chat_history}\n",
    "Question: {question}\n",
    "Review the provided chat history and the follow-up question.\n",
    "If the follow-up question builds upon the chat history,\n",
    "reformulate it into a clear, standalone question that\n",
    "incorporates necessary context. If the follow-up question\n",
    "is already clear and self-contained, leave it unchanged.\n",
    "Your goal is to ensure the question is understandable without\n",
    "needing to refer back to the chat history.\"\"\"\n",
    "\n",
    "\n",
    "question_gen_prompt = ChatPromptTemplate.from_template(question_generator_template)\n",
    "\n",
    "question_gen_chain = (\n",
    "    {\"chat_history\": RunnablePassthrough(), \"question\": RunnablePassthrough()}\n",
    "    | question_gen_prompt\n",
    "    | question_model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
    "                    not contained in the context, say \"answer not available in context\" \\n\\n\n",
    "                    Context: \\n {context}?\\n\n",
    "                    question: {question}\\n\n",
    "                    Answer:\n",
    "                  \"\"\"\n",
    "\n",
    "model_prompt = ChatPromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | model_prompt\n",
    "    | Gemini\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_response(user_question):\n",
    "    model_question = question_gen_chain.invoke({\"chat_history\":memory.buffer, \"question\": user_question})\n",
    "\n",
    "    output = model_response_chain.invoke(model_question)\n",
    "    \n",
    "    if output.startswith(\"answer not available in context\"):\n",
    "        output = model_response_chain.invoke(user_question)\n",
    "        memory.save_context({\"question\": user_question}, {\"response\": output})\n",
    "        return output\n",
    "    else:\n",
    "        memory.save_context({\"question\": user_question}, {\"response\": output})\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spies are crucial for gaining knowledge of the enemy's plans and movements, which is essential for a successful military campaign.  Spies are the key to understanding the enemy's disposition, and their information is the basis for all other types of espionage. The text emphasizes that spies are a vital element of military strategy, just as water is essential for life. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = model_response(\"what are the importance of spies and intellegence\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text describes five types of spies:\n",
      "\n",
      "1. **Local Spies:** These are individuals who are employed from the inhabitants of a specific district. They provide information about the local area and its people.\n",
      "2. **Inward Spies:** These are individuals who are officials within the enemy's ranks. They provide information about the enemy's internal affairs, strategies, and plans.\n",
      "3. **Converted Spies:** These are enemy spies who have been captured or persuaded to switch sides. They are then used to provide false information to the enemy or to gain access to sensitive information.\n",
      "4. **Doomed Spies:** These are spies who are sent on a mission with the intention of being captured. They carry false information to mislead the enemy.\n",
      "5. **Surviving Spies:** These are spies who successfully infiltrate the enemy's camp and return with valuable information. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = model_response(\"explain the difference between these types\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 constant factors which govern the art of war are:\n",
      "\n",
      "1. The Moral Law\n",
      "2. Heaven\n",
      "3. Earth\n",
      "4. The Commander\n",
      "5. Method and discipline \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = model_response(\"What are the 5 constant factors which govern the art of war\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 constant factors which govern the art of war mean the following:\n",
      "\n",
      "* **The Moral Law:** The people's loyalty to their ruler, which motivates them to fight for their leader regardless of danger.\n",
      "* **Heaven:** The influence of natural elements like weather and seasons on military operations.\n",
      "* **Earth:** The geographical features of the battlefield, including distances, dangers, and terrain.\n",
      "* **The Commander:** The qualities of a successful leader, such as wisdom, sincerity, benevolence, courage, and strictness.\n",
      "* **Method and discipline:** The organization and management of the army, including its structure, ranks, supply lines, and financial control. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = model_response(\"What do they mean?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
